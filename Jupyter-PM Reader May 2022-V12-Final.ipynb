{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc150a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0864b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name: PM-reader v12\n",
    "#Creation date: 22/04/2022\n",
    "#\n",
    "# Purpose:\n",
    "# Read in all the PM data saved from Pronto and create\n",
    "# a readable CSV file that can be easily manipulated.\n",
    "# Inputs:\n",
    "# Pronto.txt - text file containing all PM data\n",
    "# Outputs:\n",
    "# TXT file to be read into Excel\n",
    "#\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "import collections\n",
    "import more_itertools\n",
    "\n",
    "#Function definitions\n",
    "def get_data(group):\n",
    "    index=1\n",
    "    while index < len(group): # Get number of lines of this block\n",
    "        if \"Frequency  Freq-UOM\" in group[index]: # Remove stray header lines\n",
    "            del group[index]                    \n",
    "        if \"Duration   Downtime\" in group[index]: # Remove stray header lines\n",
    "            del group[index]  \n",
    "        index+=1   \n",
    "                \n",
    "    # Remove the quotes from some lines\n",
    "    group_temp=group[1].replace('\"PM','PM')\n",
    "    group[1]=group_temp\n",
    "                \n",
    "    PMNo1,PMDesc1,PMlbl1=grab_PM(group[1]) # Split PM task line\n",
    "                    \n",
    "    # If PM task number is missing, add 0 and description\n",
    "    if PMlbl1[:2] != \"PM\":\n",
    "        PMNo1=\"0\"\n",
    "        PMDesc1=\" No Description\"\n",
    "        Addline=''.join(\"PM Task No: \"+PMNo1+PMDesc1+'\\n')\n",
    "        group.insert(1,Addline)\n",
    "                    \n",
    "    first_line=PMNo1.split('|')+PMDesc1.split('|') \n",
    "          \n",
    "    if \"Plant Item\" in group[4]:        \n",
    "        # group55 is the concatenated name of the plant\n",
    "        n=[12,44,25,15,10]\n",
    "        group5=(make_chunks(group[5],n))      \n",
    "        group55=group5.split('|')\n",
    "        group555 = [x[:-1] for x in group55]\n",
    "        group555 = [x.strip('\\\"\"\\s') for x in group555]  \n",
    "        group555 = [x.strip(' ') for x in group555] \n",
    "    else:\n",
    "        group555=['No Plant', 'No Plant', '01-Jan-2000', '0.0000','']\n",
    "               \n",
    "    # This section splits the second line into the various components\n",
    "    n=[9,7,9,13,20,20,5,16,13,13,14]\n",
    "    group2=(make_chunks(group[2],n))      \n",
    "    group22=group2.split('|')\n",
    "    group222 = [x[:-1] for x in group22]\n",
    "    group222 = [x.strip(' ') for x in group222]\n",
    "       \n",
    "    # Start putting info in order\n",
    "    Data_line=[first_line]+group222+ [remove_dup1(group[3])] + group555\n",
    "                                        \n",
    "    show_line2=list(more_itertools.collapse(Data_line))\n",
    "        \n",
    "    return show_line2\n",
    "\n",
    "def grab_PM(text):\n",
    "    temp2=\" \".join(text.split()) # Remove extra whitespaces  \n",
    "    empty_str=temp2.split()    \n",
    "    temp4=\" \"\n",
    "    temp5=\" \" \n",
    "    if empty_str[3].isnumeric():         \n",
    "        if len(empty_str)>4:                             # Check that PM description exists\n",
    "            temp3=temp2.lstrip().split(\":\",1)[1]         # Grab PM Task No and description from line 3\n",
    "            temp4=temp3.lstrip().split(\" \",1)[1]         # Grab description\n",
    "            temp5=temp3.split(\" \")[1]                    # Grab PM task number\n",
    "            \n",
    "    temp6=temp2.lstrip().split(\":\",1)[0]                 # Get 'PM Task No' label\n",
    "    return temp5,temp4,temp6\n",
    "\n",
    "def get_groups(seq, group_by):\n",
    "    data = []\n",
    "    for line in seq:\n",
    "        # Here the `startswith()` logic can be replaced with other\n",
    "        # condition(s) depending on the requirement.\n",
    "        if line.startswith(group_by):\n",
    "            if data:\n",
    "                line.split()\n",
    "                yield data\n",
    "                data = []\n",
    "        data.append(line)\n",
    "    if data:\n",
    "        yield data\n",
    "\n",
    "def remove_dup1(line):\n",
    "    temp3=clean_line1(line)           \n",
    "    for element in temp3[:]:\n",
    "        if (element == ''):\n",
    "            temp3.remove(element)\n",
    "    return temp3\n",
    "\n",
    "def clean_line1(lines):\n",
    "    lines=lines.strip('\\n')\n",
    "    lines=lines.split(\" \") # Split on 2 spaces, this gets rid of most of the extraneous whitespaces\n",
    "    return lines\n",
    "\n",
    "def make_chunks(s,n):\n",
    "    result = []    \n",
    "    for length in n:\n",
    "        result.append(s[:length])\n",
    "        s = s[length:]        \n",
    "    if s:\n",
    "        result.append(s)     \n",
    "    return '|'.join(result)\n",
    "\n",
    "def make_chunks2(s,n):\n",
    "    res=[]\n",
    "    for split in n:\n",
    "        temp=s[:split]\n",
    "        s=s[split:]\n",
    "        res.append(temp) \n",
    "    return ''.join(res)\n",
    "\n",
    "#Function definitions#######################################################\n",
    "\n",
    "# Import Pronto dump file\n",
    "df=pd.read_table('C:/Users/victor.odman/OneDrive - Hyne Timber/Documents/Reports/Pronto_TB.txt',header=None,delimiter=\"\\t\", engine='python')\n",
    "  \n",
    "# Move File title to last position\n",
    "target_row = df.iloc[[0],:]\n",
    "df = df.shift(-1)\n",
    "df.iloc[-1] = target_row.squeeze()\n",
    "\n",
    "df = df[df[0].str.contains(\"LIVE\") == False] # Remove lines containing \"LIVE\"\n",
    "\n",
    "df.to_csv('pandas.txt', header=None, index=None, sep='\\t', mode='w')\n",
    "\n",
    "First_Pass=True # Trigger for handling first block of text\n",
    "mylines = []    # Declare an empty list\n",
    "with open ('Prontotext-TB.txt','w', encoding='utf-8') as outfile:                  # Open Prontotext.txt for writing text data.\n",
    "    with open ('pandas.txt', 'rt', encoding='utf8', errors='ignore') as infile: # Open pandas.txt for reading text data.\n",
    "        outfile.write(\"WO ID|PM Task No|PM Task Description|Frequency|Freq-UOM|Work Type|Resp Code|KIT|Blank|Tools Required|Lab1|Lab2|Lab3|Lab4|Duration|Downtime|Start Time|Status|Priority|Reset|Qty|Qty2|Qty3|Qty4|Plant Item|Description|Last Done|Next Due Value|Monitor|Task No.|Task Description|Item Code|Material Description|Mat Qty|Cost Centre|UOM\\n\")         \n",
    "        for i, group in enumerate(get_groups(infile, \"===\"), start=1):  \n",
    "            # This section sets up the column headers based on the text file\n",
    "             \n",
    "            # Get relevant numbers and write to outfile\n",
    "            show_line2=get_data(group)   \n",
    "                                    \n",
    "            # Length of current group\n",
    "            group_len=len(group) - 1\n",
    "            \n",
    "            # Index for start of task and safety descriptions\n",
    "            index_Desc = [i for i, s in enumerate(group) if 'Description: ' in s]\n",
    "            index_Safety = [i for i, s in enumerate(group) if 'Safety: ' in s]\n",
    "            index_Materials = [i for i, s in enumerate(group) if 'Materials:    Item Code ' in s]\n",
    "                                    \n",
    "            # Check if Description tasks exist\n",
    "            idx_min=''.join(map(str, index_Desc))            \n",
    "            if idx_min==\"\":\n",
    "                idx_min=len(group) \n",
    "            # Check if Safety tasks exist\n",
    "            idx_mid=''.join(map(str, index_Safety))            \n",
    "            if idx_mid==\"\":\n",
    "                idx_mid=len(group) \n",
    "            # Check if Materials exist\n",
    "            idx_max=''.join(map(str, index_Materials))            \n",
    "            if idx_max==\"\":\n",
    "                idx_max=len(group)\n",
    "                                    \n",
    "            # Grab the Task description and safety tasks numbers\n",
    "            #===================================================\n",
    "            Work_tasks=[]\n",
    "            Work_tasks1=[]\n",
    "            Safety_tasks=[]\n",
    "            Materials=[]\n",
    "            \n",
    "            # Work task numbers and descriptions\n",
    "            for tasks in group[int(idx_min):int(idx_mid)]:\n",
    "                # First line of task descriptions\n",
    "                if \"Description: \" in tasks:\n",
    "                    tasks1=(tasks.replace(\"Description:\",\"\"))\n",
    "                    tasks1_no=re.findall(r'^.+\\d+\\.\\d\\d',tasks1)\n",
    "                    tasks1_desc=re.findall(r'(?<=.\\d\\d ).+\\w+',tasks1)\n",
    "                    Work_tasks1.append(' ')\n",
    "                    Work_tasks1.extend(show_line2)\n",
    "                    Work_tasks1.append(tasks1_no)\n",
    "                    Work_tasks1.append(tasks1_desc)                     \n",
    "                    Work_tasks1+='\\n'                    \n",
    "                else:\n",
    "                    # All other task descriptions\n",
    "                    n=[22,80,100]\n",
    "                    group_tasks=(make_chunks(tasks,n))                     \n",
    "                    tasks_no=group_tasks.split('|')[0]                     \n",
    "                    tasks_no=tasks_no.rstrip(\"\\n\")   \n",
    "                    tasks_no=tasks_no.lstrip(\"\\\"\")                    \n",
    "                    tasks_desc=group_tasks.split('|')[1]  \n",
    "                    #tasks_desc=group_tasks.lstrip('\\\"')\n",
    "                    Work_tasks.extend(show_line2)\n",
    "                    Work_tasks.append(tasks_no)\n",
    "                    Work_tasks.append(tasks_desc)  \n",
    "                    Work_tasks+='\\n'\n",
    "                                                                                                    \n",
    "            # Safety task numbers and descriptions    \n",
    "            for s_tasks in group[int(idx_mid):int(idx_max)]:\n",
    "                # First line of safety tasks\n",
    "                if \"Safety: \" in s_tasks:\n",
    "                    tasks2=(s_tasks.replace(\"Safety:\",\"\"))\n",
    "                    tasks2_no=re.findall(r'\\d.\\d\\d',tasks2)\n",
    "                    tasks2_desc=re.findall(r'(?<=.\\d\\d ).+\\w+',tasks2)\n",
    "                    Safety_tasks.extend(show_line2)\n",
    "                    Safety_tasks.append(tasks2_no)\n",
    "                    Safety_tasks.append(tasks2_desc) \n",
    "                    Safety_tasks+='\\n'\n",
    "                else:\n",
    "                    s_tasks_no=re.findall(r'(^.+\\d+\\.\\d\\d)',s_tasks)\n",
    "                    s_tasks_desc=re.findall(r'(?<=.\\d\\d ).+\\w+',s_tasks)\n",
    "                    Safety_tasks.extend(show_line2)\n",
    "                    Safety_tasks.append(s_tasks_no)\n",
    "                    Safety_tasks.append(s_tasks_desc) \n",
    "                    Safety_tasks+='\\n'\n",
    "                    \n",
    "                # Materials    \n",
    "            for m_tasks in group[int(idx_max):len(group)]:\n",
    "                # First line of materials\n",
    "                if \"Materials:    Item Code \" in m_tasks:\n",
    "                    continue                                        \n",
    "                else:\n",
    "                    n=[21,53,14,15,10,5]\n",
    "                    m1_tasks=(make_chunks(m_tasks,n))\n",
    "                    m2_tasks=m1_tasks.strip()\n",
    "                    m_tasks1,m_tasks2,m_tasks3,m_tasks4,m_tasks5,m_tasks6=m2_tasks.split('|')                    \n",
    "                    Materials.extend(show_line2)\n",
    "                    Materials.append('')\n",
    "                    Materials.append('')\n",
    "                    Materials.append(m_tasks1)  \n",
    "                    Materials.append(m_tasks2)\n",
    "                    Materials.append(m_tasks3)\n",
    "                    Materials.append(m_tasks4)\n",
    "                    Materials.append(m_tasks5)\n",
    "                    Materials+='\\n'\n",
    "                                        \n",
    "            #===================================================  \n",
    "            \n",
    "            all_work_tasks=Work_tasks1+Work_tasks+Safety_tasks+Materials\n",
    "                        \n",
    "            show_line1=list(more_itertools.collapse(all_work_tasks))\n",
    "                        \n",
    "            show_line2='|'.join(show_line1)  # Join all strings\n",
    "            \n",
    "            show_line3=list(more_itertools.collapse(show_line2))\n",
    "                        \n",
    "            outfile.writelines(show_line3)   # write to file \n",
    "                            \n",
    "    infile.close() # Close reading file\n",
    "outfile.close() # Close writing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f91d899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f59ddd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8c546d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b559f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
